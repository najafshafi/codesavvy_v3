[
      {
        "question": "Create a Python program to read a CSV file and display its contents.",
        "solution": "import pandas as pd\n\ndf = pd.read_csv('data.csv')\nprint(df)"
      },
      {
        "question": "Write a Python script to calculate the mean, median, and mode of a list of numbers.",
        "solution": "import statistics\n\nnumbers = [1, 2, 3, 4, 5]\nmean = statistics.mean(numbers)\nmedian = statistics.median(numbers)\nmode = statistics.mode(numbers)\nprint('Mean:', mean)\nprint('Median:', median)\nprint('Mode:', mode)"
      },
      {
        "question": "Create a program to perform linear regression on a dataset using Python's scikit-learn library.",
        "solution": "import numpy as np\nfrom sklearn.linear_model import LinearRegression\n\n# Assuming X and y are loaded from data\nX = np.array([[1], [2], [3], [4]])\ny = np.array([3, 5, 7, 9])\n\nmodel = LinearRegression()\nmodel.fit(X, y)\n\nprint('Intercept:', model.intercept_)\nprint('Coefficient:', model.coef_)"
      },
      {
        "question": "Write a Python function to calculate the cosine similarity between two vectors.",
        "solution": "from numpy import dot\nfrom numpy.linalg import norm\n\ndef cosine_similarity(a, b):\n    cos_sim = dot(a, b) / (norm(a) * norm(b))\n    return cos_sim\n\nvector1 = [1, 2, 3]\nvector2 = [4, 5, 6]\nprint('Cosine Similarity:', cosine_similarity(vector1, vector2))"
      },
      {
        "question": "Create a Python script to perform k-means clustering on a dataset using scikit-learn.",
        "solution": "import numpy as np\nfrom sklearn.cluster import KMeans\n\n# Assuming X is loaded from data\nX = np.array([[1, 2], [1, 4], [1, 0],\n              [4, 2], [4, 4], [4, 0]])\n\nkmeans = KMeans(n_clusters=2, random_state=0).fit(X)\n\nprint('Cluster Centers:', kmeans.cluster_centers_)"
      },
      {
        "question": "Write a Python program to perform Principal Component Analysis (PCA) on a dataset.",
        "solution": "import numpy as np\nfrom sklearn.decomposition import PCA\n\n# Assuming X is loaded from data\nX = np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9]])\n\npca = PCA(n_components=2)\nprincipal_components = pca.fit_transform(X)\n\nprint('Principal Components:', principal_components)"
      },
      {
        "question": "Create a Python function to calculate the entropy of a given list of probabilities.",
        "solution": "import math\n\ndef entropy(probabilities):\n    entropy_value = 0\n    for prob in probabilities:\n        entropy_value -= prob * math.log2(prob)\n    return entropy_value\n\nprobabilities = [0.5, 0.3, 0.2]\nprint('Entropy:', entropy(probabilities))"
      },
      {
        "question": "Write a Python script to perform sentiment analysis using NLTK on a text dataset.",
        "solution": "import nltk\nfrom nltk.sentiment.vader import SentimentIntensityAnalyzer\n\nnltk.download('vader_lexicon')\n\n# Assuming text_data is loaded from data\ntext_data = ['This is a positive review.', 'This is a negative review.']\n\nsid = SentimentIntensityAnalyzer()\nfor text in text_data:\n    print(text)\n    scores = sid.polarity_scores(text)\n    for key in sorted(scores):\n        print('{0}: {1}, '.format(key, scores[key]), end='')\n    print()"
      },
      {
        "question": "Create a Python function to implement the Apriori algorithm for association rule mining.",
        "solution": "from itertools import combinations\n\n# Assuming transactions is loaded from data\ntransactions = [['milk', 'bread', 'butter'], ['bread', 'butter'], ['milk', 'bread']]\nmin_support = 2\n\ndef apriori(transactions, min_support):\n    itemsets = []\n    for transaction in transactions:\n        for item in transaction:\n            if not {item} in itemsets:\n                itemsets.append({item})\n    print('Frequent Itemsets:', itemsets)\n\napriori(transactions, min_support)"
      },
      {
        "question": "Write a Python program to train and test a machine learning model using cross-validation.",
        "solution": "from sklearn.model_selection import cross_val_score\nfrom sklearn.datasets import load_iris\nfrom sklearn.linear_model import LogisticRegression\n\n# Assuming X and y are loaded from data\nX, y = load_iris(return_X_y=True)\nmodel = LogisticRegression(max_iter=1000)\nscores = cross_val_score(model, X, y, cv=5)\nprint('Cross-Validation Scores:', scores)"
      },
      {
        "question": "Create a Python script to perform text preprocessing (tokenization, stemming, stop-word removal) using NLTK.",
        "solution": "import nltk\nfrom nltk.corpus import stopwords\nfrom nltk.stem import PorterStemmer\n\nnltk.download('punkt')\nnltk.download('stopwords')\n\n# Assuming text is loaded from data\ntext = \"This is a sample text for tokenization and stemming.\"\n\ntokens = nltk.word_tokenize(text)\nstop_words = set(stopwords.words('english'))\nfiltered_tokens = [word for word in tokens if word.lower() not in stop_words]\nps = PorterStemmer()\nstemmed_tokens = [ps.stem(word) for word in filtered_tokens]\n\nprint('Filtered Tokens:', filtered_tokens)\nprint('Stemmed Tokens:', stemmed_tokens)"
      },
      {
        "question": "Write a Python program to implement a decision tree classifier using scikit-learn.",
        "solution": "from sklearn.datasets import load_iris\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.metrics import accuracy_score\n\n# Assuming X and y are loaded from data\nX, y = load_iris(return_X_y=True)\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n\nmodel = DecisionTreeClassifier()\nmodel.fit(X_train, y_train)\n\ny_pred = model.predict(X_test)\naccuracy = accuracy_score(y_test, y_pred)\nprint('Accuracy:', accuracy)"
      },
      {
        "question": "Create a Python script to perform hierarchical clustering on a dataset using scipy.",
        "solution": "import numpy as np\nimport matplotlib.pyplot as plt\nfrom scipy.cluster.hierarchy import dendrogram, linkage\n\n# Assuming X is loaded from data\nX = np.array([[1, 2], [1, 4], [1, 0], [4, 2], [4, 4], [4, 0]])\n\nlinked = linkage(X, 'single')\nlabelList = range(1, len(X) + 1)\n\nplt.figure(figsize=(10, 7))\ndendrogram(linked,\n            orientation='top',\n            labels=labelList,\n            distance_sort='descending',\n            show_leaf_counts=True)\nplt.show()"
      },
      {
        "question": "Write a Python function to implement the PageRank algorithm for a directed graph.",
        "solution": "import networkx as nx\n\n# Create a directed graph\nG = nx.DiGraph()\nG.add_edges_from([(1, 2), (1, 3), (2, 1), (3, 2)])\n\n# Calculate PageRank\npagerank = nx.pagerank(G)\n\nprint('PageRank:', pagerank)"
      },
      {
        "question": "Create a Python program to perform text classification using a Naive Bayes classifier.",
        "solution": "from sklearn.datasets import fetch_20newsgroups\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.naive_bayes import MultinomialNB\nfrom sklearn.metrics import accuracy_score\n\n# Load data\nnewsgroups_train = fetch_20newsgroups(subset='train')\nnewsgroups_test = fetch_20newsgroups(subset='test')\n\n# Vectorize text data\nvectorizer = TfidfVectorizer()\nX_train = vectorizer.fit_transform(newsgroups_train.data)\nX_test = vectorizer.transform(newsgroups_test.data)\n\n# Train Naive Bayes classifier\nmodel = MultinomialNB()\nmodel.fit(X_train, newsgroups_train.target)\n\n# Predict\ny_pred = model.predict(X_test)\n\n# Evaluate\naccuracy = accuracy_score(newsgroups_test.target, y_pred)\nprint('Accuracy:', accuracy)"
      },
      {
        "question": "Create a Python script to perform sentiment analysis using a pre-trained BERT model.",
        "solution": "from transformers import pipeline\n\n# Load sentiment analysis pipeline\nclassifier = pipeline('sentiment-analysis')\n\ntext = 'I love using this product!'\nresult = classifier(text)\n\nprint('Sentiment Analysis Result:', result)"
      },
      {
        "question": "Write a Python program to perform text summarization using the Gensim library.",
        "solution": "from gensim.summarization import summarize\n\n# Assuming text is loaded from data\ntext = \"Text to summarize...\"\n\nsummary = summarize(text)\n\nprint('Summary:', summary)"
      },
      {
        "question": "Create a Python function to implement the expectation-maximization (EM) algorithm for Gaussian Mixture Models (GMM).",
        "solution": "from sklearn.mixture import GaussianMixture\n\n# Assuming X is loaded from data\nX = [[0.5], [1.0], [-1.0], [2.0]]\n\n# Initialize GMM model\ngmm = GaussianMixture(n_components=2)\ngmm.fit(X)\n\nprint('Means:', gmm.means_)\nprint('Covariances:', gmm.covariances_)"
      },
      {
        "question": "Write a Python script to perform feature selection using Recursive Feature Elimination (RFE) with a support vector machine (SVM) classifier.",
        "solution": "from sklearn.datasets import make_friedman1\nfrom sklearn.feature_selection import RFE\nfrom sklearn.svm import SVR\n\n# Generate synthetic dataset\nX, y = make_friedman1(n_samples=50, n_features=10, random_state=0)\n\n# Initialize RFE with SVM\nestimator = SVR(kernel='linear')\nselector = RFE(estimator, n_features_to_select=5, step=1)\nselector = selector.fit(X, y)\n\nprint('Selected Features:', selector.support_)"
      },
      {
        "question": "Create a Python program to implement the AdaBoost algorithm for classification using decision trees.",
        "solution": "from sklearn.ensemble import AdaBoostClassifier\nfrom sklearn.datasets import make_classification\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score\n\n# Generate synthetic dataset\nX, y = make_classification(n_samples=100, n_features=20, random_state=0)\n\n# Split data into train and test sets\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n\n# Initialize AdaBoost classifier\nmodel = AdaBoostClassifier(n_estimators=50, random_state=0)\nmodel.fit(X_train, y_train)\n\n# Predict\ny_pred = model.predict(X_test)\n\n# Evaluate\naccuracy = accuracy_score(y_test, y_pred)\nprint('Accuracy:', accuracy)"
      }
    ]